{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_GeomGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "byYdCq-g7spP"
      },
      "source": [
        "#!sudo lsb_release -a"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY98kaoB6ysr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dc786f-94e9-41c2-872d-e6def65e0c63"
      },
      "source": [
        "!pip install dgl-0.3-cp37-cp37m-manylinux1_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dgl==0.3 from file:///content/dgl-0.3-cp37-cp37m-manylinux1_x86_64.whl in /usr/local/lib/python3.7/dist-packages (0.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.3) (2.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.3) (1.19.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl==0.3) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH8uqHSBsMhM",
        "outputId": "1e4b92c7-a5ff-4c0d-fca9-020a10a8bf77"
      },
      "source": [
        "!pip uninstall -y networkx"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling networkx-2.5:\n",
            "  Successfully uninstalled networkx-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPOEDo4k9Fbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3324881-93f3-4868-f476-6d141fd6855e"
      },
      "source": [
        "!pip install networkx-2.5-py3-none-any.whl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./networkx-2.5-py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.5) (4.4.2)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.7 which is incompatible.\u001b[0m\n",
            "Installing collected packages: networkx\n",
            "Successfully installed networkx-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1IahxRHx8TI",
        "outputId": "6ffced56-f753-40b3-df4a-a3d10f7ef1cb"
      },
      "source": [
        "!pip uninstall -y imgaug"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling imgaug-0.2.7:\n",
            "  Successfully uninstalled imgaug-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbdYZz_9uvaI",
        "outputId": "18d8faf3-7dcd-421b-9622-8cd8eaaf2fd4"
      },
      "source": [
        "!pip install imgaug-0.2.7-py3-none-any.whl"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./imgaug-0.2.7-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (1.4.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (0.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.7) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.7) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.7) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.7) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.7) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.7) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.7) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.7) (4.4.2)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.7 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imgaug\n",
            "Successfully installed imgaug-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpoWTg201aAb"
      },
      "source": [
        "#!pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/dgl-0.3-cp35-cp35m-win_amd64.whl\n",
        "#!pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/dgl-0.3-cp36-cp36m-win_amd64.whl\n",
        "#!pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/dgl-0.3-cp37-cp37m-win_amd64.whl"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74cg74536i86"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqFVNZ6H7mhn"
      },
      "source": [
        "#!pip install dgl\n",
        "#install -c dglteam dgl-cuda11.0\n",
        "#!pip install dgl-cu110\n",
        "#!pip install tensorboardX"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veHAXzo4yr9y"
      },
      "source": [
        "#!pip uninstall tensorboardX"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLqCJfD4y0vo",
        "outputId": "af7be352-a836-4ff1-aa18-c0c9374821c1"
      },
      "source": [
        "!pip install tensorboardX-2.1-py2.py3-none-any.whl"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX==2.1 from file:///content/tensorboardX-2.1-py2.py3-none-any.whl in /usr/local/lib/python3.7/dist-packages (2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.1) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.1) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.1) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX==2.1) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiAqQ4nOS-gF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48c4ba1-aac6-4d72-f4e6-d0556ff78e3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wraT_KneTCy3"
      },
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/\"\n",
        "#path=\"/content/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n",
        "!python utils.py\n",
        "!python utils_data.py\n",
        "!python utils_layers.py"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-r_qU658rG"
      },
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "import json\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import dgl.init\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorboardX\n",
        "import torch as th\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import utils_data\n",
        "from utils_layers import GeomGCNNet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0wwMnHcWg4"
      },
      "source": [
        "args={'model':'GeomGCN_TwoLayers',\n",
        "  'dataset':'cora',\n",
        "  'dataset_embedding':'poincare',\n",
        "  'num_hidden':32,\n",
        "  'num_heads_layer_one':1,\n",
        "  'num_heads_layer_two':1,\n",
        "  'layer_one_ggcn_merge':'cat',\n",
        "  'layer_two_ggcn_merge':'mean',\n",
        "  'layer_one_channel_merge':'cat',\n",
        "  'layer_two_channel_merge':'mean',\n",
        "  'dropout_rate':0.5,\n",
        "  'learning_rate':0.2,\n",
        "  'weight_decay_layer_one':5e-06,\n",
        "  'weight_decay_layer_two':5e-06,\n",
        "  'num_epochs_patience':100,\n",
        "  'num_epochs_max':5000,\n",
        "  'run_id':0,\n",
        "  'dataset_split':'splits/cora_split_0.6_0.2_0.npz',\n",
        "  'learning_rate_decay_patience':50,\n",
        "  'learning_rate_decay_factor':0.8\n",
        "   }"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_P0MvqUlawQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0b24b2-16b5-4468-c41b-689c3dfc76eb"
      },
      "source": [
        "import os\n",
        "path=\".\"\n",
        "#path=\"/content/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['文稿',\n",
              " '照片',\n",
              " '软件安装包',\n",
              " '资源种子',\n",
              " 'Avengers.Infinity.War.2018.2160p.BluRay.REMUX.HEVC.DTS-HD.MA.TrueHD.7.1.Atmos-FGT.mkv',\n",
              " 'EBSCO',\n",
              " 'Colab Notebooks',\n",
              " 'Untitled0.ipynb',\n",
              " '未命名项目.gscript',\n",
              " 'Untitled1.ipynb',\n",
              " 'Untitled (2)',\n",
              " 'Lab 4 ex.ipynb',\n",
              " 'DL_lab2.ipynb',\n",
              " 'Untitled (1)',\n",
              " '__pycache__',\n",
              " '.ipynb_checkpoints',\n",
              " 'data',\n",
              " 'embedding_method_combinations_all',\n",
              " 'splits',\n",
              " 'utils.py',\n",
              " 'Anyfile Notepad Files',\n",
              " 'runs',\n",
              " 'dgl-0.3-cp35-cp35m-manylinux1_x86_64.whl',\n",
              " 'dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl',\n",
              " 'dgl-0.3-cp37-cp37m-manylinux1_x86_64.whl',\n",
              " 'dgl-0.3-cp37-cp37m-win_amd64.whl',\n",
              " 'dgl-0.4rc191005-cp37-cp37m-manylinux1_x86_64.whl',\n",
              " 'structural_neighborhood',\n",
              " 'networkx-2.5-py3-none-any.whl',\n",
              " 'Untitled',\n",
              " 'imgaug-0.2.7-py3-none-any.whl',\n",
              " 'tensorboardX-2.1-py2.py3-none-any.whl',\n",
              " 'utils_data.py',\n",
              " 'utils_layers.py',\n",
              " 'Others',\n",
              " 'test.csv',\n",
              " 'test_GeomGCN_TwoLayers_ExperimentTwoAll_cora_poincare.csv',\n",
              " 'Test_Result',\n",
              " 'Other_GCN',\n",
              " 'new_data',\n",
              " 'unconnected_nodes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKvi0Y3u1hwp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "b4c3aa0c-a500-40d0-c086-365c685a048a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    record = pd.DataFrame(columns=['Train Loss', 'Val Loss', 'Train Acc', 'Val Acc'])\n",
        "    '''\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dataset', type=str)\n",
        "    parser.add_argument('--num_hidden', type=int)\n",
        "    parser.add_argument('--num_heads_layer_one', type=int)\n",
        "    parser.add_argument('--num_heads_layer_two', type=int)\n",
        "    parser.add_argument('--layer_one_ggcn_merge', type=str, default='cat')\n",
        "    parser.add_argument('--layer_two_ggcn_merge', type=str, default='mean')\n",
        "    parser.add_argument('--layer_one_channel_merge', type=str, default='cat')\n",
        "    parser.add_argument('--layer_two_channel_merge', type=str, default='mean')\n",
        "    parser.add_argument('--dropout_rate', type=float)\n",
        "    parser.add_argument('--learning_rate', type=float)\n",
        "    parser.add_argument('--weight_decay_layer_one', type=float)\n",
        "    parser.add_argument('--weight_decay_layer_two', type=float)\n",
        "    parser.add_argument('--num_epochs_patience', type=int, default=100)\n",
        "    parser.add_argument('--num_epochs_max', type=int, default=5000)\n",
        "    parser.add_argument('--run_id', type=str)\n",
        "    parser.add_argument('--dataset_split', type=str)\n",
        "    parser.add_argument('--learning_rate_decay_patience', type=int, default=50)\n",
        "    parser.add_argument('--learning_rate_decay_factor', type=float, default=0.8)\n",
        "    args = parser.parse_args()\n",
        "    vars(args)['model'] = 'GeomGCN_TwoLayers_ExperimentTwoAll'\n",
        "    '''\n",
        "\n",
        "    #print(\"test\")\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    if args['dataset_split'] == 'jknet':\n",
        "        g, features, labels, train_mask, val_mask, test_mask, num_features, num_labels = utils_data.load_data(\n",
        "            args.dataset, None, 0.6, 0.2, 'GeomGCN',args['dataset_embedding'])\n",
        "    else:\n",
        "        g, features, labels, train_mask, val_mask, test_mask, num_features, num_labels = utils_data.load_data(\n",
        "            args['dataset'], args['dataset_split'], None, None, 'GeomGCN', args['dataset_embedding'])\n",
        "        \n",
        "    print(time.time() - t1)\n",
        "\n",
        "    # 图初始化\n",
        "    g.set_n_initializer(dgl.init.zero_initializer)\n",
        "    g.set_e_initializer(dgl.init.zero_initializer)\n",
        "    \n",
        "    #构建网络\n",
        "    net = GeomGCNNet(g=g, num_input_features=num_features, num_output_classes=num_labels, num_hidden=args[\"num_hidden\"],\n",
        "                     num_divisions=25, dropout_rate=args[\"dropout_rate\"],\n",
        "                     num_heads_layer_one=args[\"num_heads_layer_one\"], num_heads_layer_two=args[\"num_heads_layer_two\"],\n",
        "                     layer_one_ggcn_merge=args[\"layer_one_ggcn_merge\"],\n",
        "                     layer_one_channel_merge=args[\"layer_one_channel_merge\"],\n",
        "                     layer_two_ggcn_merge=args[\"layer_two_ggcn_merge\"],\n",
        "                     layer_two_channel_merge=args[\"layer_two_channel_merge\"])\n",
        "\n",
        "    #构建优化器\n",
        "    optimizer = th.optim.Adam([{'params': net.geomgcn1.parameters(), 'weight_decay': args[\"weight_decay_layer_one\"]},\n",
        "                               {'params': net.geomgcn2.parameters(), 'weight_decay': args[\"weight_decay_layer_two\"]}],\n",
        "                              lr=args[\"learning_rate\"])\n",
        "    \n",
        "    learning_rate_scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,factor=args[\"learning_rate_decay_factor\"],patience=args[\"learning_rate_decay_patience\"])\n",
        "    writer = tensorboardX.SummaryWriter(logdir=f'runs/{args[\"model\"]}_{args[\"run_id\"]}')\n",
        "\n",
        "    features = features.to(\"cpu\")\n",
        "    labels = labels.to(\"cpu\")\n",
        "    train_mask = train_mask.to(\"cpu\")\n",
        "    val_mask = val_mask.to(\"cpu\")\n",
        "    test_mask = test_mask.to(\"cpu\")\n",
        "\n",
        "    # Adapted from https://github.com/PetarV-/GAT/blob/master/execute_cora.py\n",
        "    patience = args[\"num_epochs_patience\"]\n",
        "    vlss_mn = np.inf\n",
        "    vacc_mx = 0.0\n",
        "    vacc_early_model = None\n",
        "    vlss_early_model = None\n",
        "    state_dict_early_model = None\n",
        "    curr_step = 0\n",
        "\n",
        "    print(\"epoch\")\n",
        "    # Adapted from https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html\n",
        "    dur = []\n",
        "    test_time = 0.0\n",
        "    for epoch in range(20):\n",
        "        t0 = time.time()\n",
        "\n",
        "        net.train()\n",
        "        train_logits = net(features)\n",
        "        train_logp = F.log_softmax(train_logits, 1)\n",
        "        train_loss = F.nll_loss(train_logp[train_mask], labels[train_mask])\n",
        "        #train_loss = Variable(train_loss.data, requires_grad=True)\n",
        "\n",
        "        train_pred = train_logp.argmax(dim=1)\n",
        "        train_acc = th.eq(train_pred[train_mask], labels[train_mask]).float().mean().item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        net.eval()\n",
        "        with th.no_grad():\n",
        "            val_logits = net(features)\n",
        "            val_logp = F.log_softmax(val_logits, 1)\n",
        "            val_loss = F.nll_loss(val_logp[val_mask], labels[val_mask]).item()\n",
        "            val_pred = val_logp.argmax(dim=1)\n",
        "            val_acc = th.eq(val_pred[val_mask], labels[val_mask]).float().mean().item()\n",
        "\n",
        "        learning_rate_scheduler.step(val_loss)\n",
        "\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "        print(\n",
        "            \"Epoch {:05d} | Train Loss {:.4f} | Train Acc {:.4f} | Val Loss {:.4f} | Val Acc {:.4f} | Time(s) {:.4f}\".format(\n",
        "                epoch, train_loss.item(), train_acc, val_loss, val_acc, sum(dur) / len(dur)))\n",
        "\n",
        "        writer.add_scalar('Train Loss', train_loss.item(), epoch)\n",
        "        writer.add_scalar('Val Loss', val_loss, epoch)\n",
        "        writer.add_scalar('Train Acc', train_acc, epoch)\n",
        "        writer.add_scalar('Val Acc', val_acc, epoch)\n",
        "\n",
        "        test_time += (sum(dur) / len(dur))\n",
        "\n",
        "        new={'Train Loss':train_loss.item(),'Val Loss':val_loss,'Train Acc':train_acc,'Val Acc':val_acc}\n",
        "        \n",
        "        record=record.append(new,ignore_index=True)   # ignore_index=True,表示不按原来的索引，从0开始自动递增\n",
        "\n",
        "        # Adapted from https://github.com/PetarV-/GAT/blob/master/execute_cora.py\n",
        "        if val_acc >= vacc_mx or val_loss <= vlss_mn:\n",
        "            if val_acc >= vacc_mx and val_loss <= vlss_mn:\n",
        "                vacc_early_model = val_acc\n",
        "                vlss_early_model = val_loss\n",
        "                state_dict_early_model = net.state_dict()\n",
        "            vacc_mx = np.max((val_acc, vacc_mx))\n",
        "            vlss_mn = np.min((val_loss, vlss_mn))\n",
        "            curr_step = 0\n",
        "        else:\n",
        "            curr_step += 1\n",
        "            if curr_step >= patience:\n",
        "                print()\n",
        "#                break\n",
        "\n",
        "    #drive.mount(\"/content\")\n",
        "    record.to_csv('Test_Result/test_{model}_{dataset}_{embedding}_{rec_time}.csv'.format(model=args[\"model\"], dataset=args[\"dataset\"], embedding=args['dataset_embedding'], rec_time=test_time))\n",
        "    print(test_time)\n",
        "\n",
        "    net.load_state_dict(state_dict_early_model)\n",
        "    net.eval()\n",
        "    with th.no_grad():\n",
        "        test_logits = net(features)\n",
        "        test_logp = F.log_softmax(test_logits, 1)\n",
        "        test_loss = F.nll_loss(test_logp[test_mask], labels[test_mask]).item()\n",
        "        test_pred = test_logp.argmax(dim=1)\n",
        "        test_acc = th.eq(test_pred[test_mask], labels[test_mask]).float().mean().item()\n",
        "        test_hidden_features = net.geomgcn1(features).cpu().numpy()\n",
        "\n",
        "        final_train_pred = test_pred[train_mask].cpu().numpy()\n",
        "        final_val_pred = test_pred[val_mask].cpu().numpy()\n",
        "        final_test_pred = test_pred[test_mask].cpu().numpy()\n",
        "\n",
        "    '''\n",
        "    results_dict = vars(args)\n",
        "    results_dict['test_loss'] = test_loss\n",
        "    results_dict['test_acc'] = test_acc\n",
        "    results_dict['actual_epochs'] = 1 + epoch\n",
        "    results_dict['val_acc_max'] = vacc_mx\n",
        "    results_dict['val_loss_min'] = vlss_mn\n",
        "    results_dict['total_time'] = sum(dur)\n",
        "    with open(os.path.join('runs', f'{args.model}_{args.run_id}_results.txt'), 'w') as outfile:\n",
        "        outfile.write(json.dumps(results_dict) + '\\n')\n",
        "    np.savez_compressed(os.path.join('runs', f'{args.model}_{args.run_id}_hidden_features.npz'),\n",
        "                        hidden_features=test_hidden_features)\n",
        "    np.savez_compressed(os.path.join('runs', f'{args.model}_{args.run_id}_final_train_predictions.npz'),\n",
        "                        final_train_predictions=final_train_pred)\n",
        "    np.savez_compressed(os.path.join('runs', f'{args.model}_{args.run_id}_final_val_predictions.npz'),\n",
        "                        final_val_predictions=final_val_pred)\n",
        "    np.savez_compressed(os.path.join('runs', f'{args.model}_{args.run_id}_final_test_predictions.npz'),\n",
        "                        final_test_predictions=final_test_pred)\n",
        "    '''                   "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test1\n",
            "test2\n",
            "test3\n",
            "test6\n",
            "<class 'dgl.graph.DGLGraph'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test_end\n",
            "5.248006582260132\n",
            "图初始化\n",
            "构建网络\n",
            "构建优化器\n",
            "设置学习率\n",
            "开始epoch\n",
            "Epoch 00000 | Train Loss 1.9459 | Train Acc 0.1267 | Val Loss 1.9446 | Val Acc 0.2965 | Time(s) 1.6282\n",
            "Epoch 00001 | Train Loss 1.9440 | Train Acc 0.2970 | Val Loss 1.9367 | Val Acc 0.2965 | Time(s) 1.6325\n",
            "Epoch 00002 | Train Loss 1.9342 | Train Acc 0.2970 | Val Loss 1.9182 | Val Acc 0.2965 | Time(s) 1.6131\n",
            "Epoch 00003 | Train Loss 1.9112 | Train Acc 0.2970 | Val Loss 1.8911 | Val Acc 0.2977 | Time(s) 1.6061\n",
            "Epoch 00004 | Train Loss 1.8739 | Train Acc 0.2970 | Val Loss 1.8603 | Val Acc 0.2977 | Time(s) 1.6023\n",
            "Epoch 00005 | Train Loss 1.8290 | Train Acc 0.2970 | Val Loss 1.8274 | Val Acc 0.2965 | Time(s) 1.5984\n",
            "Epoch 00006 | Train Loss 1.7813 | Train Acc 0.2970 | Val Loss 1.7924 | Val Acc 0.2965 | Time(s) 1.5958\n",
            "Epoch 00007 | Train Loss 1.7429 | Train Acc 0.2978 | Val Loss 1.7559 | Val Acc 0.2965 | Time(s) 1.5911\n",
            "Epoch 00008 | Train Loss 1.7020 | Train Acc 0.2970 | Val Loss 1.7170 | Val Acc 0.2965 | Time(s) 1.5897\n",
            "Epoch 00009 | Train Loss 1.6630 | Train Acc 0.2970 | Val Loss 1.6758 | Val Acc 0.2977 | Time(s) 1.5900\n",
            "Epoch 00010 | Train Loss 1.6235 | Train Acc 0.2970 | Val Loss 1.6350 | Val Acc 0.2977 | Time(s) 1.5926\n",
            "Epoch 00011 | Train Loss 1.5888 | Train Acc 0.2987 | Val Loss 1.5981 | Val Acc 0.2965 | Time(s) 1.5947\n",
            "Epoch 00012 | Train Loss 1.5585 | Train Acc 0.2987 | Val Loss 1.5657 | Val Acc 0.2965 | Time(s) 1.5948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c1eda2d826cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0m_is_legacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}